{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bassemr/DeepLearningAndGenerativeModelsCourse/blob/main/ex5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "436cd3c4-5d34-4820-b1ed-6be4c0739e93",
      "metadata": {
        "id": "436cd3c4-5d34-4820-b1ed-6be4c0739e93"
      },
      "source": [
        "# CNN vs MLPPP\n",
        "In this notebook it will be showed how to train a CNN and what are its advantages (and disanvantages) with respect to a fully connected network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd788809-d878-4c4c-ac10-2457880c5b00",
      "metadata": {
        "id": "cd788809-d878-4c4c-ac10-2457880c5b00"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd8dfccd-aa38-433c-bf97-11196763a355",
      "metadata": {
        "id": "bd8dfccd-aa38-433c-bf97-11196763a355"
      },
      "outputs": [],
      "source": [
        "# function to count number of parameters\n",
        "def get_n_params(model):\n",
        "    np=0\n",
        "    for p in list(model.parameters()):\n",
        "        np += p.nelement()\n",
        "    return np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4211b204-67e2-4f3a-aeb6-328e45f08f0b",
      "metadata": {
        "id": "4211b204-67e2-4f3a-aeb6-328e45f08f0b"
      },
      "source": [
        "## Dataset Loading\n",
        "First step we need to load the dataset that will be used for train and test.\n",
        "\n",
        "In this case MNIST dataset will be used. MNIST consist in black and white images of handwritten digits between 0-9.\n",
        "\n",
        "Pytorch Dataloaders will be used for this task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f329a51-c2ca-404d-8b04-42c56dc7125e",
      "metadata": {
        "id": "7f329a51-c2ca-404d-8b04-42c56dc7125e"
      },
      "outputs": [],
      "source": [
        "input_size  = 28*28   # images are 28x28 pixels\n",
        "output_size = 10      # there are 10 classes\n",
        "\n",
        "# TRAIN dataset\n",
        "# Pytorch already has some datasets available for downlaod\n",
        "train_dataset = datasets.MNIST('../data', train=True, download=True,\n",
        "                       # transforms that we want to apply when iterating the dataset\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       # mean and std of MNIST dataset\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))\n",
        "\n",
        "# The dataloader will iterate through the dataset and load the data in memory\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "                        train_dataset,\n",
        "                        batch_size=64, shuffle=True)\n",
        "\n",
        "# TEST dataset\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=1000, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35da7a46-3778-4225-baef-456c3d16d93a",
      "metadata": {
        "id": "35da7a46-3778-4225-baef-456c3d16d93a"
      },
      "outputs": [],
      "source": [
        "print(len(train_dataset), len(train_loader)) #WHY?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63e5dbf3-3317-4db1-83aa-2e36fa218d12",
      "metadata": {
        "id": "63e5dbf3-3317-4db1-83aa-2e36fa218d12"
      },
      "outputs": [],
      "source": [
        "# plotting libs\n",
        "from res.plot_lib import plot_data, plot_model, set_default\n",
        "set_default()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9d8f5ac-0093-43a4-83d7-be458323bf86",
      "metadata": {
        "id": "f9d8f5ac-0093-43a4-83d7-be458323bf86"
      },
      "outputs": [],
      "source": [
        "# show some images\n",
        "def denorm_mnist(x):\n",
        "    m = 0.1307\n",
        "    std = 0.3081\n",
        "    # denormalization operation = std*x + m\n",
        "    return x*std + m\n",
        "\n",
        "to_pil = transforms.ToPILImage()\n",
        "plt.figure(figsize=(16, 6))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    image, _ = train_loader.dataset.__getitem__(i) # load one image\n",
        "    plt.imshow(to_pil(denorm_mnist(image)))\n",
        "    plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4494f259-b9c6-4edb-bf13-eedb2edbfcd6",
      "metadata": {
        "id": "4494f259-b9c6-4edb-bf13-eedb2edbfcd6"
      },
      "source": [
        "## Network Definition\n",
        "Let's define an MLP and a CNN to solve the MNIST digit classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f08da12a-4dd9-42de-8900-fecabec661b8",
      "metadata": {
        "id": "f08da12a-4dd9-42de-8900-fecabec661b8"
      },
      "outputs": [],
      "source": [
        "# MLP\n",
        "class FC2Layer(nn.Module):\n",
        "    def __init__(self, input_size, n_hidden, output_size):\n",
        "        super(FC2Layer, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_size, n_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(n_hidden, n_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(n_hidden, output_size),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, self.input_size) # flatten\n",
        "        return self.network(x)\n",
        "\n",
        "# CNN\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, input_size, n_feature, output_size):\n",
        "        super(CNN, self).__init__()\n",
        "        self.n_feature = n_feature\n",
        "\n",
        "        self.conv_block1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=n_feature, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2))\n",
        "\n",
        "        self.conv_block2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=n_feature, out_channels=n_feature, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2))\n",
        "\n",
        "        self.fc1 = nn.Linear(n_feature*4*4, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x, verbose=False):\n",
        "        x = self.conv_block1(x) # what is the output size?\n",
        "        x = self.conv_block2(x) # what is the output size?\n",
        "        x = x.view(-1, self.n_feature*4*4) # flatten\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b89131d8-3e7d-4a01-b6f7-5ab6c912bbad",
      "metadata": {
        "id": "b89131d8-3e7d-4a01-b6f7-5ab6c912bbad"
      },
      "outputs": [],
      "source": [
        "# set device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83fec976-2594-4333-ae34-c50dbb7b2081",
      "metadata": {
        "id": "83fec976-2594-4333-ae34-c50dbb7b2081"
      },
      "outputs": [],
      "source": [
        "# define train and test function\n",
        "accuracy_list = []\n",
        "def train(epoch, model, optimizer, perm=None):\n",
        "    model.train()\n",
        "    # dataloader will iterate the dataset and return images (data)\n",
        "    # and labels (target)\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # send to device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # permute pixels\n",
        "        data = data.view(-1, 28*28)\n",
        "        data = data[:, perm]\n",
        "        data = data.view(-1, 1, 28, 28)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "def test(model, perm=None):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        # send to device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # permute pixels\n",
        "        data = data.view(-1, 28*28)\n",
        "        data = data[:, perm]\n",
        "        data = data.view(-1, 1, 28, 28)\n",
        "        output = model(data)\n",
        "        test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    accuracy_list.append(accuracy)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be3da76c-6b08-40f1-b28c-751e11a6c698",
      "metadata": {
        "id": "be3da76c-6b08-40f1-b28c-751e11a6c698"
      },
      "outputs": [],
      "source": [
        "n_hidden = 8 # number of hidden units\n",
        "\n",
        "model_fnn = FC2Layer(input_size, n_hidden, output_size)\n",
        "model_fnn.to(device)\n",
        "optimizer = optim.SGD(model_fnn.parameters(), lr=0.01, momentum=0.5)\n",
        "print('Number of parameters: {}'.format(get_n_params(model_fnn)))\n",
        "\n",
        "for epoch in range(0, 1):\n",
        "    train(epoch, model_fnn, optimizer)\n",
        "    test(model_fnn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "053418da-d315-4860-99e3-f65e9d5a8ca6",
      "metadata": {
        "id": "053418da-d315-4860-99e3-f65e9d5a8ca6"
      },
      "outputs": [],
      "source": [
        "# Training settings\n",
        "n_features = 6 # number of feature maps\n",
        "\n",
        "\n",
        "model_cnn = CNN(input_size, n_features, output_size)\n",
        "model_cnn.to(device)\n",
        "optimizer = optim.SGD(model_cnn.parameters(), lr=0.01, momentum=0.5)\n",
        "print('Number of parameters: {}'.format(get_n_params(model_cnn)))\n",
        "\n",
        "for epoch in range(0, 1):\n",
        "    train(epoch, model_cnn, optimizer)\n",
        "    test(model_cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9f831af-b1c4-4016-a1a4-96fdff3e774a",
      "metadata": {
        "id": "e9f831af-b1c4-4016-a1a4-96fdff3e774a"
      },
      "source": [
        "The CNN performs much better that an MLP on images.\n",
        "\n",
        "Now let's try to shuffle the pixels!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29e84413-4a7a-4628-8ee2-56c9f8e5e6f4",
      "metadata": {
        "id": "29e84413-4a7a-4628-8ee2-56c9f8e5e6f4"
      },
      "outputs": [],
      "source": [
        "perm = torch.randperm(784)\n",
        "plt.figure(figsize=(16, 12))\n",
        "for i in range(10):\n",
        "    image, _ = train_loader.dataset.__getitem__(i)\n",
        "    # permute pixels\n",
        "    image_perm = image.view(-1, 28*28).clone()\n",
        "    image_perm = image_perm[:, perm]\n",
        "    image_perm = image_perm.view(-1, 1, 28, 28)\n",
        "    plt.subplot(4, 5, i + 1)\n",
        "    plt.imshow(to_pil(denorm_mnist(image.squeeze())))\n",
        "    plt.axis('off')\n",
        "    plt.subplot(4, 5, i + 11)\n",
        "    plt.imshow(to_pil(denorm_mnist(image_perm.squeeze())))\n",
        "    plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0cff7c8-22ec-4f42-b39c-6114743b58d0",
      "metadata": {
        "id": "d0cff7c8-22ec-4f42-b39c-6114743b58d0"
      },
      "source": [
        "### How the CNN will perform now?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f467d096-71b5-46e4-baaf-18332821b7f3",
      "metadata": {
        "id": "f467d096-71b5-46e4-baaf-18332821b7f3"
      },
      "outputs": [],
      "source": [
        "# Training settings\n",
        "n_features = 6 # number of feature maps\n",
        "\n",
        "model_cnn = CNN(input_size, n_features, output_size)\n",
        "model_cnn.to(device)\n",
        "optimizer = optim.SGD(model_cnn.parameters(), lr=0.01, momentum=0.5)\n",
        "print('Number of parameters: {}'.format(get_n_params(model_cnn)))\n",
        "\n",
        "for epoch in range(0, 1):\n",
        "    train(epoch, model_cnn, optimizer, perm)\n",
        "    test(model_cnn, perm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c65a14e-3923-4473-92e4-619b880743e7",
      "metadata": {
        "id": "4c65a14e-3923-4473-92e4-619b880743e7"
      },
      "source": [
        "### How about the MLP?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e0b3f64-c948-40f1-af46-e0e46dfbfd13",
      "metadata": {
        "id": "6e0b3f64-c948-40f1-af46-e0e46dfbfd13"
      },
      "outputs": [],
      "source": [
        "n_hidden = 8    # number of hidden units\n",
        "\n",
        "model_fnn = FC2Layer(input_size, n_hidden, output_size)\n",
        "model_fnn.to(device)\n",
        "optimizer = optim.SGD(model_fnn.parameters(), lr=0.01, momentum=0.5)\n",
        "print('Number of parameters: {}'.format(get_n_params(model_fnn)))\n",
        "\n",
        "for epoch in range(0, 1):\n",
        "    train(epoch, model_fnn, optimizer, perm)\n",
        "    test(model_fnn, perm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4231526d-b194-477f-a36b-e013853ca5bf",
      "metadata": {
        "id": "4231526d-b194-477f-a36b-e013853ca5bf"
      },
      "source": [
        "### The CNN performances dropped!!!\n",
        "WHY? The concept of locality was lost: pixel are no longer stationary on a grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a01ec1c8-a8ce-4bc0-b0cc-c8cfe16fed09",
      "metadata": {
        "id": "a01ec1c8-a8ce-4bc0-b0cc-c8cfe16fed09"
      },
      "outputs": [],
      "source": [
        "plt.bar(('NN image', 'CNN image',\n",
        "         'CNN scrambled', 'NN scrambled'),\n",
        "        accuracy_list, width=0.4, color = ['red', 'green', 'green', 'red'])\n",
        "plt.ylim((min(accuracy_list)-5, 96))\n",
        "plt.ylabel('Accuracy [%]')\n",
        "plt.title('Performance comparison');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bd62491-cd2a-4b7c-a457-89f50aa28851",
      "metadata": {
        "id": "4bd62491-cd2a-4b7c-a457-89f50aa28851"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}